{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJdgbpoMZ2oI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "import re\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "twitter_df=pd.read_csv(\"N:\\Machine learning\\Algorithms\\sentiment_analysis\\\\train.csv\")\n",
        "# print(twitter_df.head())\n",
        "# print(twitter_df.info())\n",
        "twitter_df=twitter_df.dropna()\n",
        "twitter_df = twitter_df.reset_index()\n",
        "# print(twitter_df.isnull().any())\n",
        "\n",
        "\n",
        "twitter_df=twitter_df.drop(['textID'],axis=1)\n",
        "# print(twitter_df.info())\n",
        "stopset = set(stopwords.words(\"english\"))\n",
        "\n",
        "# twitter_df[\"selected_text\"]=twitter_df[\"selected_text\"].str.strip().str.lower()\n",
        "# twitter_df[\"text\"]=twitter_df[\"text\"].str.strip().str.lower()\n",
        "\n",
        "twitter_df['sentiment'] = twitter_df['sentiment'].map({'positive': 1,'negative': -1,'neutral': 0},na_action=None)\n",
        "\n",
        "count=sns.countplot(data= twitter_df, x= 'sentiment',order = twitter_df['sentiment'].value_counts().index)\n",
        "plt.show()\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "\n",
        "\n",
        "#--------EDA----------------\n",
        "\n",
        "\n",
        "\n",
        "positive = twitter_df[twitter_df['sentiment'] == 1]\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (10, 10)\n",
        "plt.style.use('fast')\n",
        "\n",
        "wc = WordCloud(background_color = 'orange', width = 1500, height = 1500).generate(str(positive['text']))\n",
        "plt.title('Description Positive', fontsize = 15)\n",
        "\n",
        "plt.imshow(wc)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "negative = twitter_df[twitter_df['sentiment'] == -1]\n",
        "plt.rcParams['figure.figsize'] = (10, 10)\n",
        "plt.style.use('fast')\n",
        "wc = WordCloud(background_color = 'orange', width = 1500, height = 1500).generate(str(negative['text']))\n",
        "plt.title('Description Negative', fontsize = 15)\n",
        "plt.imshow(wc)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "neutral = twitter_df[twitter_df['sentiment'] == 0]\n",
        "plt.rcParams['figure.figsize'] = (10, 10)\n",
        "plt.style.use('fast')\n",
        "wc = WordCloud(background_color = 'orange', width = 1500, height = 1500).generate(str(neutral['text']))\n",
        "plt.title('Description Neutral', fontsize = 15)\n",
        "plt.imshow(wc)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "y=twitter_df['sentiment']\n",
        "\n",
        "x=twitter_df['selected_text']\n",
        "\n",
        "#----------- removing punctuations, stopwords, hyperlinks and tokenizing ---------\n",
        "corpus = []\n",
        "for i in range(0, len(x)):\n",
        "  twitter = re.sub(r\"@[A-Za-z0-9]+\", ' ', x[i])\n",
        "  twitter = re.sub(r\"https?://[A-Za-z0-9./]+\", ' ', x[i])\n",
        "  twitter = re.sub(r\"[^a-zA-Z.!?]\", ' ', x[i])\n",
        "  twitter = re.sub(r\" +\", ' ', x[i])\n",
        "  twitter = twitter.split()\n",
        "  ps = PorterStemmer()\n",
        "  twitter = [ps.stem(word) for word in twitter if not word in set(stopwords.words('english'))]\n",
        "  twitter = ' '.join(twitter)\n",
        "  corpus.append(twitter)\n",
        "\n",
        "cv = CountVectorizer(stop_words='english')\n",
        "\n",
        "x=cv.fit_transform(corpus)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,stratify=y,test_size=0.2,random_state=5)\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "model = MultinomialNB()\n",
        "model.fit(x_train,y_train)\n",
        "\n",
        "\n",
        "y_pred=model.predict(x_test)\n",
        "\n",
        "# y_train=y_train.reshape(-1,1)\n",
        "# y_test=y_test.reshape(-1,1)\n",
        "\n",
        "\n",
        "\n",
        "print(\"Accuracy Score = \",accuracy_score(y_test,y_pred))              \n",
        "print(\"precision score = \",precision_score(y_test, y_pred,average='weighted'))         \n",
        "print(\"recall score = \",recall_score(y_test, y_pred,average='micro'))               \n",
        "print(\"f1 score = \",f1_score(y_test, y_pred, average='weighted'))\n",
        "errors = abs(y_pred - y_test)\n",
        "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n",
        "\n"
      ]
    }
  ]
}