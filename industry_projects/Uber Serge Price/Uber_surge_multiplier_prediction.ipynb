{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Basic Libraries: Numpy and Pandas to handle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the corresponding data files usind Pandas' read_csv function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather=pd.read_csv(\"weather.csv\",delimiter=',')\n",
    "rides=pd.read_csv(\"cab_rides.csv\",delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the timestamp into the desirable format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>cab_type</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>destination</th>\n",
       "      <th>source</th>\n",
       "      <th>price</th>\n",
       "      <th>surge_multiplier</th>\n",
       "      <th>id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>name</th>\n",
       "      <th>date_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.44</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>1544952607890</td>\n",
       "      <td>North Station</td>\n",
       "      <td>Haymarket Square</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>424553bb-7174-41ea-aeb4-fe06d4f4b9d7</td>\n",
       "      <td>lyft_line</td>\n",
       "      <td>Shared</td>\n",
       "      <td>2018-12-16 09:30:07.890000128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.44</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>1543284023677</td>\n",
       "      <td>North Station</td>\n",
       "      <td>Haymarket Square</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4bd23055-6827-41c6-b23b-3c491f24e74d</td>\n",
       "      <td>lyft_premier</td>\n",
       "      <td>Lux</td>\n",
       "      <td>2018-11-27 02:00:23.676999936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.44</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>1543366822198</td>\n",
       "      <td>North Station</td>\n",
       "      <td>Haymarket Square</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>981a3613-77af-4620-a42a-0c0866077d1e</td>\n",
       "      <td>lyft</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>2018-11-28 01:00:22.197999872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.44</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>1543553582749</td>\n",
       "      <td>North Station</td>\n",
       "      <td>Haymarket Square</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>c2d88af2-d278-4bfd-a8d0-29ca77cc5512</td>\n",
       "      <td>lyft_luxsuv</td>\n",
       "      <td>Lux Black XL</td>\n",
       "      <td>2018-11-30 04:53:02.749000192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.44</td>\n",
       "      <td>Lyft</td>\n",
       "      <td>1543463360223</td>\n",
       "      <td>North Station</td>\n",
       "      <td>Haymarket Square</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>e0126e1f-8ca9-4f2e-82b3-50505a09db9a</td>\n",
       "      <td>lyft_plus</td>\n",
       "      <td>Lyft XL</td>\n",
       "      <td>2018-11-29 03:49:20.223000064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   distance cab_type     time_stamp    destination            source  price  \\\n",
       "0      0.44     Lyft  1544952607890  North Station  Haymarket Square    5.0   \n",
       "1      0.44     Lyft  1543284023677  North Station  Haymarket Square   11.0   \n",
       "2      0.44     Lyft  1543366822198  North Station  Haymarket Square    7.0   \n",
       "3      0.44     Lyft  1543553582749  North Station  Haymarket Square   26.0   \n",
       "4      0.44     Lyft  1543463360223  North Station  Haymarket Square    9.0   \n",
       "\n",
       "   surge_multiplier                                    id    product_id  \\\n",
       "0               1.0  424553bb-7174-41ea-aeb4-fe06d4f4b9d7     lyft_line   \n",
       "1               1.0  4bd23055-6827-41c6-b23b-3c491f24e74d  lyft_premier   \n",
       "2               1.0  981a3613-77af-4620-a42a-0c0866077d1e          lyft   \n",
       "3               1.0  c2d88af2-d278-4bfd-a8d0-29ca77cc5512   lyft_luxsuv   \n",
       "4               1.0  e0126e1f-8ca9-4f2e-82b3-50505a09db9a     lyft_plus   \n",
       "\n",
       "           name                     date_time  \n",
       "0        Shared 2018-12-16 09:30:07.890000128  \n",
       "1           Lux 2018-11-27 02:00:23.676999936  \n",
       "2          Lyft 2018-11-28 01:00:22.197999872  \n",
       "3  Lux Black XL 2018-11-30 04:53:02.749000192  \n",
       "4       Lyft XL 2018-11-29 03:49:20.223000064  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rides['date_time'] = pd.to_datetime(rides['time_stamp']/1000, unit='s')\n",
    "\n",
    "weather['date_time'] = pd.to_datetime(weather['time_stamp'], unit='s')\n",
    "\n",
    "rides.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a coloumn 'merge_date' containing date merged with the location so that we can join the two dataframes on this basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rides['merge_date'] = rides.source.astype(str) +\" - \"+ rides.date_time.dt.date.astype(\"str\") +\" - \"+ rides.date_time.dt.hour.astype(\"str\")\n",
    "weather['merge_date'] = weather.location.astype(str) +\" - \"+ weather.date_time.dt.date.astype(\"str\") +\" - \"+ weather.date_time.dt.hour.astype(\"str\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the index to merge_date column so joining the two datasets will not generate any error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.index = weather['merge_date']\n",
    "\n",
    "final_dataframe = rides.join(weather,on=['merge_date'],rsuffix ='_w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the null values rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataframe=final_dataframe.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make different columns of day and hour to simplify the format of date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataframe['day'] = final_dataframe.date_time.dt.dayofweek\n",
    "final_dataframe['hour'] = final_dataframe.date_time.dt.hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We ignored surge value of more than 3 because the samples are very less for surge_multiplier>3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "surge_dataframe = final_dataframe[final_dataframe.surge_multiplier < 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature selection--> we are selecting the most relevant features from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "x = surge_dataframe[['distance','day','hour','temp','clouds', 'pressure','humidity', 'wind', 'rain']]\n",
    "\n",
    "y=surge_dataframe['surge_multiplier']\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "#ignoring multiplier of 3 as there are only 2 values in our dataset\n",
    "\n",
    "le.fit([1,1.25,1.5,1.75,2.,2.25,2.5])\n",
    "y = le.transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All features to be fed to the ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['distance',\n",
       " 'day',\n",
       " 'hour',\n",
       " 'temp',\n",
       " 'clouds',\n",
       " 'pressure',\n",
       " 'humidity',\n",
       " 'wind',\n",
       " 'rain']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_list=list(x.columns)\n",
    "feature_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Dataset into train and test sets in the percentage ratio of 70:30\n",
    "\n",
    "We have used train_test_split function from scikit-learn library. One can build it from scratch as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are using SMOTE to balance out the data of different surge_multipliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "x_train, y_train = sm.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Random Forest model\n",
    "It will take some time, so please wait till the model is ready to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, n_jobs=-1, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, n_jobs=-1, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', n_jobs=-1, random_state=42)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model= RandomForestClassifier(n_jobs=-1, random_state = 42,class_weight=\"balanced\")\n",
    "\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the trained Random Forestr model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the trained model using Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted   1.00  1.25  1.50  1.75  2.00  2.50\n",
      "Actual                                        \n",
      "1.00       53717   825   435   164   147     7\n",
      "1.25         366   580    11     3     7     0\n",
      "1.50         194     4   200     7     2     0\n",
      "1.75         101     2     1   129     1     0\n",
      "2.00          65     7     3     4    99     2\n",
      "2.50           4     0     0     0     4     1\n"
     ]
    }
   ],
   "source": [
    "print(pd.crosstab(le.inverse_transform(y_test), le.inverse_transform(y_pred),rownames=['Actual'],colnames=['Predicted']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score =  0.9585581167238842\n",
      "precision score =  0.9675988630431089\n",
      "recall score =  0.9585581167238842\n",
      "f1 score =  0.9624810336482128\n",
      "Mean Absolute Error: 0.07 degrees.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(\"Accuracy Score = \",accuracy_score(y_test,y_pred))              \n",
    "print(\"precision score = \",precision_score(y_test, y_pred,average='weighted'))         \n",
    "print(\"recall score = \",recall_score(y_test, y_pred,average='micro'))\n",
    "print(\"f1 score = \",f1_score(y_test, y_pred, average='weighted'))\n",
    "\n",
    "errors = abs(y_pred - y_test)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding which feature is of what importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: distance             Importance: 0.31\n",
      "Variable: temp                 Importance: 0.13\n",
      "Variable: pressure             Importance: 0.13\n",
      "Variable: wind                 Importance: 0.13\n",
      "Variable: humidity             Importance: 0.1\n",
      "Variable: rain                 Importance: 0.1\n",
      "Variable: hour                 Importance: 0.05\n",
      "Variable: clouds               Importance: 0.04\n",
      "Variable: day                  Importance: 0.02\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get numerical feature importances\n",
    "importances = list(model.feature_importances_)\n",
    "\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It justifies that the Distance feature is the most prominant factor in deciding the surge multiplication factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
